{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Projet TC6: Criteo Display Advertising Challenge </center>\n",
    " ## <center>Rapport</center>\n",
    "<center>Trung VUTHANH,   Malik KAZI,    Nour NOUREDINE</center>\n",
    "\n",
    "###### <center>Abstract</center>\n",
    "\n",
    "Dans le cadre du projet de Science des données pour le Big Data nous avons choisit d'utiliser les données du défi Kaggle Criteo. Ce Notebook résume notre démarche en présentant le meilleur modèle que nous avons réussit à entrainer sur ce problème de classification binaire supervisé. L'exploration de ce projet nous à permis d'en apprendre plus sur le feature hash, technique que nous avons mis en place et qui à permis de réduie grandement le temps d'apprentissage et de prédiction de notre modèle en résuisant la taille de la représentation des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Décommenter la ligne suivante si findspark n'est pas installé :\n",
    "#!pip install findspark\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import re\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, desc, rand, avg, when, isnan, trim\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import FeatureHasher\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\").getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Données et pre-traitement de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont téléchargeables [ici](http://labs.criteo.com/2014/02/download-kaggle-display-advertising-challenge-dataset/?fbclid=IwAR0y5NGoecgyTheFdqT6vBjQVVIz47FCQD48aeOIfyOy-adcZcDj8iRgLJU).\n",
    "\n",
    "Elles contienent un ensemble de publicités représentées par 39 features (13 numériques en représentation \"count\" et 26 string hachés) ainsi qu'un label indiquant si la publicité à enregistré un clic ou pas. Nous sommes donc dans le cadre d'un problème de classification binaire supervisée. Les données sont scindées en deux fichiers texte d'entrainement et de tests (les informations ci-dessous sont tirées de la description du défi Kaggle) :\n",
    "\n",
    "- train.txt : L'ensemble d'entraînement consiste en une partie du trafic de Criteo sur une période de 7 jours. Chaque ligne correspond à une annonce d'affichage desservie par Criteo. Les exemples positifs (cliqués) et négatifs (sans clic) ont tous deux été sous-échantillonnés à des taux différents afin de réduire la taille du DataSet. Les exemples sont classés chronologiquement.\n",
    "\n",
    "- test.txt: Le jeu de test est calculé de la même manière que l'ensemble de train, mais pour les événements le jour suivant de l'entraînement.\n",
    "\n",
    "Dans notre traitement du problème nous n'avons pas utilisé l'ensemble de test fournis car nous n'avons pas réalisé de soumission au défi. De plus, nos premières approches ayant été longues à traiter nous avons préféré valider nos modèles sur un sous ensemble isolé et stratifié des données d'entrainement.\n",
    "\n",
    "Pour des raisons de clareté nous présentons ici que notre modèle final. Le second notebook fournis présente certaines de nos expérimentations sur d'autre modèles au cas ou vous souhaiteriez les consulter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indiquer le chemin vers le fichier train.txt dans la variable path ci \n",
    "# training_file_path ci dessous :\n",
    "training_file_path = '../criteo/dac/train.txt'\n",
    "new_file_path = '../criteo/dac/train_partition.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Création d'échantillons de données, décommenter une des ligne et relancer la cellule pour choisir le nombre\n",
    "# d'exemples à prendre en compte\n",
    "!head -200000 $training_file_path > $new_file_path\n",
    "#!head -1000000 $training_file_path > $new_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_train = sc.textFile('dac/train.txt')\n",
    "data_train = sc.textFile(new_file_path)\n",
    "# On split les tabulations \n",
    "data_train = data_train.map(lambda k : k.split('\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Création de liste contenant les noms des colonnes \n",
    "header = ['label']+['num_'+str(i) for i in range(13)]+['cat_'+str(i) for i in range(26)]\n",
    "# Création d'une liste contenant les noms de colonnes des features (sans le label)\n",
    "feature_names = header[1:]\n",
    "# Liste contenant les noms de colonnes contenant des features numériques\n",
    "numerical_feature_names = ['label']+['num_'+str(i) for i in range(13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons testé plusieurs manières de gérer les données manquantes, comme les remplacer par la valeur moyenne dans le cas des features numériques (voir second notebook) mais nous avons finalement otpé pour le retrait des exemples incomplets. Il reste cependant des Null (ce qui ne gène pas l'apprentissage). Nous avons tenté de les retirer mais cela avait eu un effet nefaste sur l'apprentissage ce qui est intriguant. Peut être que les modèles de la bibliothèque MLlib gèrent intelligeament les valeurs Null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.createDataFrame(data_train, header)\n",
    "# On ignore les examples comportants des données non renseignées\n",
    "# On convertit les Null en NaN puis on drop tout \n",
    "def to_null(c):\n",
    "    ''' Fonction récupérée sur Stackoverflow \n",
    "    '''\n",
    "    return when(~(col(c).isNull() | isnan(col(c)) | (trim(col(c)) == \"\")), col(c))\n",
    "# Nous avons commenté la ligne suivante car les performances étaient réduites en retirant les exemples \n",
    "# contenant des Null\n",
    "#df = df.select([to_null(c).alias(c) for c in df.columns])\n",
    "df = df.na.drop()\n",
    "# Converstion des features numériques en entiers \n",
    "for colname in numerical_feature_names:\n",
    "    df = df.withColumn(colname, col(colname).cast(IntegerType()))\n",
    "# Création d'un ensemble de test \n",
    "X_train, X_test = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+------+--------+--------+--------+--------+\n",
      "|label|num_0|num_1|num_2|num_3|num_4|num_5|num_6|num_7|num_8|num_9|num_10|num_11|num_12|   cat_0|   cat_1|   cat_2|   cat_3|   cat_4|   cat_5|   cat_6|   cat_7|   cat_8|   cat_9|  cat_10|  cat_11|  cat_12|  cat_13|  cat_14|  cat_15|  cat_16|  cat_17|  cat_18|  cat_19|  cat_20|cat_21|  cat_22|  cat_23|  cat_24|  cat_25|\n",
      "+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+------+--------+--------+--------+--------+\n",
      "|    0|    1|    1|    5|    0| 1382|    4|   15|    2|  181|    1|     2|  null|     2|68fd1e64|80e26c9b|fb936136|7b4723c4|25c83c98|7e0ccccf|de7995b8|1f89b562|a73ee510|a8cd5504|b2cb9c98|37c9c164|2824a5f6|1adce6ef|8ba8b39a|891b62e7|e5ba7672|f54016b9|21ddcdc9|b1252a9d|07b5194c|      |3a171ecb|c5c50484|e8b83407|9727dd16|\n",
      "|    0|    2|    0|   44|    1|  102|    8|    2|    2|    4|    1|     1|  null|     4|68fd1e64|f0cf0024|6f67f7e5|41274cd7|25c83c98|fe6b92e5|922afcc0|0b153874|a73ee510|2b53e5fb|4f1b46f3|623049e6|d7020589|b28479f6|e6c5b5cd|c92f3b61|07c540c4|b04e4670|21ddcdc9|5840adea|60f6221e|      |3a171ecb|43f13e8b|e8b83407|731c3655|\n",
      "+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+------+--------+--------+--------+--------+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- label: integer (nullable = true)\n",
      " |-- num_0: integer (nullable = true)\n",
      " |-- num_1: integer (nullable = true)\n",
      " |-- num_2: integer (nullable = true)\n",
      " |-- num_3: integer (nullable = true)\n",
      " |-- num_4: integer (nullable = true)\n",
      " |-- num_5: integer (nullable = true)\n",
      " |-- num_6: integer (nullable = true)\n",
      " |-- num_7: integer (nullable = true)\n",
      " |-- num_8: integer (nullable = true)\n",
      " |-- num_9: integer (nullable = true)\n",
      " |-- num_10: integer (nullable = true)\n",
      " |-- num_11: integer (nullable = true)\n",
      " |-- num_12: integer (nullable = true)\n",
      " |-- cat_0: string (nullable = true)\n",
      " |-- cat_1: string (nullable = true)\n",
      " |-- cat_2: string (nullable = true)\n",
      " |-- cat_3: string (nullable = true)\n",
      " |-- cat_4: string (nullable = true)\n",
      " |-- cat_5: string (nullable = true)\n",
      " |-- cat_6: string (nullable = true)\n",
      " |-- cat_7: string (nullable = true)\n",
      " |-- cat_8: string (nullable = true)\n",
      " |-- cat_9: string (nullable = true)\n",
      " |-- cat_10: string (nullable = true)\n",
      " |-- cat_11: string (nullable = true)\n",
      " |-- cat_12: string (nullable = true)\n",
      " |-- cat_13: string (nullable = true)\n",
      " |-- cat_14: string (nullable = true)\n",
      " |-- cat_15: string (nullable = true)\n",
      " |-- cat_16: string (nullable = true)\n",
      " |-- cat_17: string (nullable = true)\n",
      " |-- cat_18: string (nullable = true)\n",
      " |-- cat_19: string (nullable = true)\n",
      " |-- cat_20: string (nullable = true)\n",
      " |-- cat_21: string (nullable = true)\n",
      " |-- cat_22: string (nullable = true)\n",
      " |-- cat_23: string (nullable = true)\n",
      " |-- cat_24: string (nullable = true)\n",
      " |-- cat_25: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vérifiaction que la dataFrame est correcte \n",
    "df.show(2)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La répartition des classes dans une échantillon est présentée à la figure ci-dessous. Cette dernière est biasée vers les exemples négatifs. Une fois nos modèles entrainés, il faudra donc bien veiller a vérifier que le modèle ne predit pas uniquement la classe majoritaire ce qui donnerai à tord un bon score de précision! (Le graph ci desous est tiré du second notebook)\n",
    "\n",
    "![](class_repartition.png)\n",
    "\n",
    "## Modèle de regression linéaire\n",
    "\n",
    "Dans la section qui suit, nous créons un pipeline afin de préparer les données et d'entrainer un modèle de regression linéaire.\n",
    "\n",
    "1. En premier lieu nous appliquons la fonction FeatureHasher à nos feature. Cette méthode permet de changer les features en une représentation unique pour toutes les features qui est dans notre cas un vecteur creux à valeurs binaires. Cette représentation est calculée par une fonction de hachage appliquée à chaque features, dont le hash représentera l'indice de cette feature dans la matrice originale. A cette étape il faut bien évidement faire attention à ne pas hasher les labels mais uniquement les features. Hasher les labels aboutierait a un \"data leakage\" se manifestant par un score suspicieusement élevé lors de la validation.\n",
    "\n",
    "2. Dans une seconde étape nous entrainons un modèle de regression linéaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Hash trick' pour réduire les dimenssions des données\n",
    "hasher = FeatureHasher(inputCols=feature_names, outputCol=\"features\")\n",
    "# Modèle de regression linéaire\n",
    "lr = LogisticRegression(maxIter=4, regParam=0.1, labelCol='label')\n",
    "# Instaciation d'une pipeline \n",
    "pipeline = Pipeline(stages=[hasher, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le hash trick permet de réduire la représentation des données et accélère ainsi la phase d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.1 ms, sys: 9.22 ms, total: 41.3 ms\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle sur les données d'entrainement \n",
    "%time model = pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dans un premier temps nous avons tenté de calculer un score de précision de la manière suivante mais le temps \n",
    "# de calcul était trop lent. Nous avons laissé la trace de notre recherche et avons finalement \n",
    "#pred.registerTempTable('predictions')\n",
    "#Predictions.columns \n",
    "#df2 = sqlContext.sql(\"select prediction, label from predictions\")\n",
    "#success = sqlContext.sql(\"select prediction, label from predictions where prediction=label\").count()\n",
    "#num_pred = pred.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fonctions utiles pour calculer la précision et le log loss remerciement à notre camarade Robin Duraz. \n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def logloss(y_true, y_proba):\n",
    "    y_true = [y.__getitem__(\"label\") for y in y_true]\n",
    "    y_proba = [y.__getitem__(\"probability\") for y in y_proba]\n",
    "    y_proba = [[i for i in j] for j in y_proba]\n",
    "    return log_loss(y_true, y_proba)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = [y.__getitem__(\"label\") for y in y_true]\n",
    "    y_pred = [y.__getitem__(\"prediction\") for y in y_pred]\n",
    "    egal = [y_true[i] == y_pred[i] for i in range(len(y_true))]\n",
    "    return sum(egal)/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Les opérations de collect sont couteuses \n",
    "y_true = X_test.select(\"label\").collect()\n",
    "y_proba = pred.select(\"probability\").collect()\n",
    "y_pred = pred.select(\"prediction\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss = 0.516653, Accuracy = 76.027545%\n"
     ]
    }
   ],
   "source": [
    "l = logloss(y_true, y_proba)\n",
    "acc = accuracy(y_true, y_pred)\n",
    "print(\"Log loss = {:2f}, Accuracy = {:2%}\".format(l, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous l'avons remarqué au début, les données sont biaisées vers les exemples négatifs. Vérifions donc que notre classifieur à bien appris et qu'il n'a pas prédit que la classe majoritaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|51126|\n",
      "|       1.0| 9139|\n",
      "+----------+-----+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|14674|\n",
      "|    0|45591|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.select(['prediction']).groupBy('prediction').count().show()\n",
    "pred.select(['label']).groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle n'a pas prédit que des 0.\n",
    "\n",
    "Dans la cellule suivante nous lançon une cross validation sur X_train. Quand nous avons testé nous avons obtenu les même résultats que précédement. Cela est surement du au fait que le modèle renvoie les prédictions du run ayant obtenu les meilleurs résultats parmis les k folds. Nous n'avons pas trouvé comment obtenir la moyenne des résultats des runs. D'autre part, si nous avions souhaité \"tuner\" nos paramètres nous aurions pu ajouter différentes valeurs à tester au ParamGridBuilder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol='label'),\n",
    "                          estimatorParamMaps = ParamGridBuilder().build(),\n",
    "                          numFolds=5)\n",
    "cvModel = crossval.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss = 0.516653, Accuracy = 76.027545%\n"
     ]
    }
   ],
   "source": [
    "pred = cvModel.transform(X_test)\n",
    "y_proba = pred.select(\"probability\").collect()\n",
    "y_pred = pred.select(\"prediction\").collect()\n",
    "l = logloss(y_true, y_proba)\n",
    "acc = accuracy(y_true, y_pred)\n",
    "print(\"Log loss = {:2f}, Accuracy = {:2%}\".format(l, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Dans ce projet nous avons exploré plusieurs méthodes de traitement des données en manipulant des dataFrames. Après diverse expériences exploratoires consignées dans le second notebook, nous avons pris en main la bibliothèque MLlib afin d'entrainer un modèle de regression linéaire. Nous avons constaté une réduction du temps d'entrainement et de prédiction en ajoutant du \"feature hashing\" à notre pipeline. La suite logique de ce travail serait de mettre en placce une pipeline plus complexe, ajoutant par exemple une représentation TF-IDF sur les features numériques car elles sont en représentation \"count\" (même si cela allourdirait la représentation précédente). D'autre part il serait intéressant de lancer notre code avec un spark submit sur l'ensemble des données et de lui ajouter une fonction d'écriture d'un fichier résultats afin de pouvoir faire une soumission sur Kaggle.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
